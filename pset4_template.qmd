---
title: "Your Title"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 
We use (`*`) to indicate a problem that we think might be time consuming. 
    
## Style Points (10 pts) 
Please refer to the minilesson on code style
**[here](https://uchicago.zoom.us/rec/share/pG_wQ-pHTQrJTmqNn4rcrw5V194M2H2s-2jdy8oVhWHkd_yZt9o162IWurpA-fxU.BIQlSgZLRYctvzp-)**.

## Submission Steps (10 pts)
1. This problem set is a paired problem set.
2. Play paper, scissors, rock to determine who goes first. Call that person *Partner 1*.
    - Partner 1 (name and cnet ID):
    - Partner 2 (name and cnet ID):
3. Partner 1 will accept the `ps4` and then share the link it creates with their partner. You can only share it with one partner so you will not be able to change it after your partner has accepted. 
4. "This submission is our work alone and complies with the 30538 integrity policy." Add your initials to indicate your agreement: \*\*\_\_\*\* \*\*\_\_\*\*
5. "I have uploaded the names of anyone else other than my partner and I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  (1 point)
6. Late coins used this pset: \*\*\_\_\*\* Late coins left after submission: \*\*\_\_\*\*
7. Knit your `ps4.qmd` to an PDF file to make `ps4.pdf`, 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
8. (Partner 1): push  `ps4.qmd` and `ps4.pdf` to your github repo.
9. (Partner 1): submit `ps4.pdf` via Gradescope. Add your partner on Gradescope.
10. (Partner 1): tag your submission in Gradescope

**Important:** Repositories are for tracking code. **Do not commit the data or shapefiles to your repo.** The best way to do this is with `.gitignore`, which we have covered in class. If you do accidentally commit the data, Github has a [guide](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github#removing-files-from-a-repositorys-history). The best course of action depends on whether you have pushed yet. This also means that both partners will have to download the initial raw data and any data cleaning code will need to be re-run on both partners' computers. 

## Download and explore the Provider of Services (POS) file (10 pts)

import packages
```{python}
import pandas as pd
import numpy as np
import altair as alt
import os
import json
alt.renderers.enable("png") 
import shapely
import geopandas
```

1. 
```{python}
raw_health = "/Users/justinesilverstein/Desktop/problem-set-4-andrew-justine"
path_health16 = os.path.join(raw_health, "pos2016.csv")
health16 = pd.read_csv(path_health16) 

path_health17 = os.path.join(raw_health, "pos2017.csv")
health17 = pd.read_csv(path_health17)

path_health18 = os.path.join(raw_health, "pos2018.csv")
health18 = pd.read_csv(path_health18, encoding = "ISO-8859-1")

path_health19 = os.path.join(raw_health, "pos2019.csv")
health19 = pd.read_csv(path_health19, encoding = "ISO-8859-1")
```

Attribution: I asked ChatGPT how to solve the unicode errors I 
was encountering, and I was advised to try out different
encodings, including "ISO-8859-1".

Q1 Answer:
```{python}
variables_list = health16.columns

print("These are the variables I selected: ", variables_list)
```


2. 
Function for subsetting the datasets to short term hospitals
```{python}
def short_term(X):
  Y = X[(X["PRVDR_CTGRY_SBTYP_CD"] == 1) & (X["PRVDR_CTGRY_CD"] == 1)]
  return(Y)

```

Run function on health16
```{python}
short16 = short_term(health16)

print("There are ", len(short16), " hospitals in this dataset")
```

    a.
    b.
3. 

short term function on health17
```{python}
short17 = short_term(health17)

```

short term function on health18
```{python}
short18 = short_term(health18)

```

```{python}
short19 = short_term(health19)

```

Appending the data together
```{python}
# add a "year" column to each dataset, for future disagg
def add_column(X, the_year):
  year_col = []
  i = 0
  while i < len(X):
    year_col.append(the_year)
    i += 1
  X["Year"] = year_col
  return(X)

#run on each dataframe
add_column(short16, 2016)

add_column(short17, 2017)

add_column(short18, 2018)

add_column(short19, 2019)
```

Attribution: I asked my code why my len(X) and length of index
values were not equal, and was advised to set i equal to 0 
instead of 1. 

Concat the dataframes together
```{python}

concat_1 = pd.concat([short16, short17], axis = 0, ignore_index = True)

concat_2 = pd.concat([concat_1, short18], axis = 0, ignore_index = True)

df_health = pd.concat([concat_2, short19], axis = 0, ignore_index = True)

```

Attribution: https://datacarpentry.org/python-ecology-lesson/05-merging-data.html 

Adding an observation variable to the dataframe
```{python}
def  one_dummy(C):
  observation = []
  i = 0
  while 1 > 0 and i < C:
    observation.append(1)
    i += 1
  return(observation)

#add observation column to df
df_health["Observation"] = one_dummy(len(df_health))

```

Attribution: modifying my own code from Pset 1

Graph observations by year
```{python}
alt.data_transformers.enable("vegafusion")

alt.Chart(df_health).mark_bar().encode(
  alt.X("Year:N"),
  alt.Y("sum(Observation)")
)


```

4.

```{python}
# create a function to iterate through PRVDR_NUM 
def unique_comp(column):
  unique_box = []
  for entry in column:
    if entry not in unique_box:
      unique_box.append(entry)
    else:
      pass
  return(unique_box)

#save list
unique_list = unique_comp(df_health["PRVDR_NUM"])

```

Filter by year in order to make numbers for each year, save those numbers to a df
```{python}
# make series with the four years
the_years = [2016, 2017, 2018, 2019]

#2016
unique_len_16 = len(unique_comp(df_health["PRVDR_NUM"][df_health["Year"] == 2016]))

#2017
unique_len_17 = len(unique_comp(df_health["PRVDR_NUM"][df_health["Year"] == 2017]))

#2018
unique_len_18 = len(unique_comp(df_health["PRVDR_NUM"][df_health["Year"] == 2018]))

#2019
unique_len_19 = len(unique_comp(df_health["PRVDR_NUM"][df_health["Year"] == 2019]))

# make the lens into a list
len_list = [unique_len_16, unique_len_17, unique_len_18, unique_len_19]

#form into dataframe

the_data = {
  "Years": the_years,
   "Unique_CMS": len_list 
}

df_CMS = pd.DataFrame(the_data)

```

Plot the graph
```{python}
alt.Chart(df_CMS).mark_bar().encode(
  alt.X("Years:N"),
  alt.Y("Unique_CMS")
)


```

Attribution: https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/ 
    a.
    b.

## Identify hospital closures in POS file (15 pts) (*)

1. Create a list of all hospitals that were active in 2016 that were suspected to have closed by 2019. Record the facility name and zip of each hospital as well as the year of suspected closure. How many hospitals fit in this definition?

filter for hospitals that appear in 2016 as active (Termination code should be active provider) and then check if they disappear from the data

so if termination code == 00, active provider
if 01 then voluntary merger or closure, so maybe pull out datasets where code == 0 and set in four datasets by year then compare fac_nam? 

use if/else loops, to fill a dataframe with hospitals active in 2016 but terminated either in 2017, 2018, or 2019 along with facility name, zip code, and year terminated

```{python}
#filter for a dataset of active hospitals in 2016
active_2016 = df_health[(df_health['PGM_TRMNTN_CD'] == 0) & (df_health['Year'] == 2016)]

active_2017 = df_health[(df_health['PGM_TRMNTN_CD'] == 0) & (df_health['Year'] == 2017)]

active_2018 = df_health[(df_health['PGM_TRMNTN_CD'] == 0) & (df_health['Year'] == 2018)]

active_2019 = df_health[(df_health['PGM_TRMNTN_CD'] == 0) & (df_health['Year'] == 2019)]

```

2. Sort this list of hospitals by name and report the names and year of suspected closure for the first 10 rows.


3. Not all closures are true closures, remove any suspected closures that are zipcodes where the number does not decrease in the year after the suspected closure.

    a. Among the suspected closures, how many hospitals fit this definition? After correcting, how many do you have left?

    b. Sort this list of corrected hospital closures by name and report the first ten rows.

## Download Census zip code shapefile (10 pt) 

1. 
    a. The five file types in this download are DBF files, PRJ files,
     SHP files, SHX files, and xmlfile

    b. 
2. 

## Calculate zip codeâ€™s distance to the nearest hospital (20 pts) (*)

1. 
2. 
3. 
4. 
    a.
    b.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
2. 
3. 
4. 

## Reflecting on the exercise (10 pts) 
